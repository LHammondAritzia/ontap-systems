---
sidebar: upgrade-arl-manual_sidebar
permalink: upgrade-arl-manual/check_configure_uta_uta2_node3.html
summary: Check and configure UTA/UTA2 ports on node 3
---

= Check and configure UTA/UTA2 ports on node3
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

[.lead]
// COPIED FROM 9.8 GUIDE...CHECK FOR REUSE, THEN REMMOVE THIS COMMENT
If node3 has onboard UTA/UTA2 ports or a UTA/UTA2 card, you must check the configuration of the ports and possibly reconfigure them, depending on how you want to use the upgraded system.

.Before you begin

You must have the correct SFP+ modules for the UTA/UTA2 ports.

.About this task

If you want to use a Unified Target Adapter (UTA/UTA2) port for FC, you must first verify how the port is configured.

NOTE: NetApp marketing materials might use the term UTA2 to refer to CNA adapters and ports. However, the CLI uses the term CNA.

You can use the ucadmin show command to verify the current port configuration:

----
*> ucadmin show
          Current  Current    Pending  Pending    Admin
 Adapter  Mode     Type       Mode     Type       Status
 -------  -------  ---------  -------  ---------  -----------
 0e       fc       target     -        initiator  offline
 0f       fc       target     -        initiator  offline
 0g       fc       target     -        initiator  offline
 0h       fc       target     -        initiator  offline
 1a       fc       target     -        -          online
 1b       fc       target     -        -          online
6 entries were displayed.
----

UTA/UTA2 ports can be configured into native FC mode or UTA/UTA2 mode. FC mode supports FC initiator and FC target; UTA/UTA2 mode allows concurrent NIC and FCoE traffic sharing the same 10 GbE SFP+ interface and supports FC targets.

UTA/UTA2 ports might be found on an adapter or on the controller, and have the following configurations, but you should check the configuration of the UTA/UTA2 ports on the node3 and change it, if necessary:

* UTA/UTA2 cards ordered when the controller is ordered are configured before shipment to
have the personality you request.
* UTA/UTA2 cards ordered separately from the controller are shipped with the default FC target
personality.
* Onboard UTA/UTA2 ports on new controllers are configured before shipment to have the
personality you request.
+
NOTE: *Attention*: If your system has storage disks, you enter the commands in this section at the cluster prompt unless directed to enter Maintenance mode. If you have a VSeries system or have FlexArray Virtualization Software and are connected to storage arrays, you enter commands in this section at the Maintenance mode prompt. You must be in Maintenance mode to configure UTA/UTA2 ports.

.Steps

. Check how the ports are currently configured by taking one of the following actions:
+
[cols=35,65]
|If the system... |Then...

|Has storage disks
|No action required.
|Is a V-Series system or has FlexArray Virtualization Software and is connected to storage arrays
|Enter the following command on node3:

'ucadmin show`
|===

The system displays output similar to the following examples:

----
*> ucadmin show
         Current  Current    Pending  Pending  Admin
Adapter  Mode     Type       Mode     Type     Status
-------  -------  ---------  -------  -------  ------
0e       fc       initiator  -        -        online
0f       fc       initiator  -        -        online
0g       cna      target     -        -        online
0h       cna      target     -        -        online
0e       fc       initiator  -        -        online
0f       fc       initiator  -        -        online
0g       cna      target     -        -        online
0h       cna      target     -        -        online
*>
----

. If the current SFP+ module does not match the desired use, replace it with the correct SFP+ module.
+
Contact your NetApp representative to obtain the correct SFP+ module.

. Examine the output of the `ucadmin show` command and determine whether the UTA/UTA2 ports have the personality you want.

. Take one of the following actions:
+
[cols="35,65"]
|===
|If the UTA/UTA2 ports... |Then...

|Do not have the personality that you want
|Go to Step 5.
|Have the personality that you want
|Skip Step 5 through Step 12 and go to Step 13.
|===

. Take one of the following actions:
+
[cols="35.65"]
|===
|If you are configuring... |Then...

|Ports on a UTA/UTA2 card
|Go to Step 7.
|Onboard UTA/UTA2 ports
|Skip Step 7 and go to Step 8.
|===

. If the adapter is in initiator mode, and if the UTA/UTA2 port is online, take the UTA/UTA2 port offline:
+
`storage disable adapter adapter_name`
+
Adapters in target mode are automatically offline in Maintenance mode.

. If the current configuration does not match the desired use, change the configuration as needed:
+
`ucadmin modify -m fc|cna -t initiator|target adapter_name`
+
* -m is the personality mode, fc or cna.
* -t is the FC4 type, target or initiator.
+
NOTE: You need to use FC initiator for tape drives, FlexArray Virtualization systems, and MetroCluster configurations. You need to use the FC target for SAN clients.

. Verify the settings:
+
`ucadmin show`

. Verify the settings:
+
[cols="35,65"]
|===
|If the system... |Then...

|Has storage disks
|`ucadmin show`
|Is a V-Series system or has FlexArray Virtualization Software and is connected to storage arrays
|`ucadmin show`
|===

The output in the following example shows that the FC4 type of adapter 1b is changing to initiator and that the mode of adapters 2a and 2b is changing to cna:

----
*> ucadmin show
         Current  Current    Pending  Pending    Admin
Adapter  Mode     Type       Mode     Type       Status
-------  -------  ---------  -------  ---------  ------
1a       fc       initiator  -        -          online
1b       fc       target     -        initiator  online
2a       fc       target     cna      -          online
2b       fc       target     cna      -          online
*>
----

. Place any target ports online by entering one of the following commands, once for each port:
+
[cols="35.65"]
|===
|If the system... |Then...

|Has storage disks
|`network fcp adapter modify -node _node_name_ -adapter _adapter_name_ -state up`
|Is a V-Series system or has FlexArray Virtualization Software and is connected to storage arrays
|`fcp config _adapter_name_ up`
|===

. Cable the port.

. Take one of the following actions:
+
[cols="35.65"]
|===
|If the system... |Then...

|Has storage disks
|Go to _Verifying the node3 installation_.
|Is a V-series system or has FlexArray Virtualization Software and is connected to storage arrays
|Return to _Stage 3: XXXXXXX new title needed here Upgrading the node pair_ and resume the
section at _Step 22_.
|===

. Exit Maintenance mode:
+
`halt`

. Boot node into boot menu by running boot_ontap menu.
+
If you are upgrading to an A800, go to step 22 on page 46.

. If the system goes into a reboot loop with the message no disks found, it indicates that the system has reset the ports back to the target mode and therefore is unable to locate any disks. Continue with Steps 16 on page 45 to 21 on page 46 to resolve this.

. Press Ctrl-C during autoboot to stop the node at the LOADER> prompt.
+
At the `LOADER>` prompt, enter maintenance mode by using the following command:
+
`boot_ontap maint`

. In maintenance mode, display all the previously set initiator ports that are now in target mode. by using the following command:
+
`ucadmin show`
+
Change the ports back to initiator mode:
+
`ucadmin modify -m fc -t initiator -f _adapter_name_`

. Verify that the ports have been changed to initiator mode:
+
`ucadmin show`

. Exit maintenance mode:
+
`halt`

. At the `LOADER>` prompt, enter the following command :
+
`boot_ontap`

Now, when booting, the node is able to locate all the disks that were previously assigned to it and can boot up as expected.

. If you are upgrading from a system with external disks to a system that supports internal and external disks (AFF A800 systems, for example), set the node1 aggregate as the root aggregate to ensure node3 boots from the root aggregate of node1. To set the root aggregate, go to the boot menu and select option 5 to enter maintenance mode.
+
WARNING: You must perform the following substeps in the exact order shown; failure to do so might cause an outage or even data loss.

+
The following procedure sets node3 to boot from the root aggregate of node1:

.. Enter maintenance mode:
+
`boot_ontap maint`

.. Check the RAID, plex, and checksum information for the node1 aggregate:
+
`aggr status -r`

.. Check the status of the node1 aggregate:
+
`aggr status`

.. If necessary, bring the node1 aggregate online:
+
`aggr_online _root_aggr_from_node1_`

.. Prevent node3 from booting from its original root aggregate
+
`aggr offline _root_aggr_on_node3_`

.. Set the node1 root aggregate as the new root aggregate for node3:
+
`aggr options _aggr_from_node1_ root`

.. Verify that the root aggregate of node3 is offline and the root aggregate for the disks brought over from node1 is online and set to root:
+
`aggr status`
+
NOTE: Failing to perform the previous substep might cause node3 to boot from the internal root aggregate, or it might cause the system to assume a new  cluster configuration exists or prompt you to identify one.

+
The following shows an example of the command output:
+
----
 ----------------------------------------------------------------------
            Aggr State           Status               Options
 aggr0_nst_fas8080_15 online     raid_dp, aggr        root, nosnap=on
                                 fast zeroed
                                 64-bit

           aggr0 offline         raid_dp, aggr        diskroot
                                 fast zeroed
                                 64-bit
 ----------------------------------------------------------------------
----
